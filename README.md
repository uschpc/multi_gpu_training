# Multi-GPU Training with PyTorch: Data and Model Parallelism

### About
The material in this repo demonstrates multi-GPU training using PyTorch. Part 1 covers how to optimize single-GPU training. The necessary code changes to enable multi-GPU training using the data-parallel and model-parallel approaches are then shown. 

### Setup

Make sure you can run Python on Adroit:

```bash
$ ssh <YourNetID>@discovery.usc.edu  # VPN required if off-campus
$ git clone https://github.com/uschpc/multi_gpu_training.git
$ cd multi_gpu_training
```




